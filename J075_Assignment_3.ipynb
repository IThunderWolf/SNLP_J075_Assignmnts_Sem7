{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f55bba",
   "metadata": {},
   "source": [
    "                                                            NLP ASSIGNMENT - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60b6cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running date parser test cases...\n",
      "Test Case 1:\n",
      "  Input Text:      'The event will take place on March 5, 2023.'\n",
      "  Extracted Date:  '05/03/2023'\n",
      "  Expected Output: '05/03/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 2:\n",
      "  Input Text:      'Her birthday is on 07/08/1990.'\n",
      "  Extracted Date:  '07/08/1990'\n",
      "  Expected Output: '07/08/1990'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 3:\n",
      "  Input Text:      'The deadline is 2022-12-31.'\n",
      "  Extracted Date:  '2022/12/2031'\n",
      "  Expected Output: '31/12/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 4:\n",
      "  Input Text:      'We met on 1st of January 2000.'\n",
      "  Extracted Date:  '01/01/2000'\n",
      "  Expected Output: '01/01/2000'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 5:\n",
      "  Input Text:      'The concert is scheduled for 15th September, 2021.'\n",
      "  Extracted Date:  '15/09/2021'\n",
      "  Expected Output: '15/09/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 6:\n",
      "  Input Text:      'Let's catch up on 02.04.2022.'\n",
      "  Extracted Date:  '02/04/2022'\n",
      "  Expected Output: '02/04/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 7:\n",
      "  Input Text:      'The project started on 5/6/19.'\n",
      "  Extracted Date:  '05/06/2019'\n",
      "  Expected Output: '05/06/2019'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 8:\n",
      "  Input Text:      'He was born on 1987/11/23.'\n",
      "  Extracted Date:  '1987/11/2023'\n",
      "  Expected Output: '23/11/1987'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 9:\n",
      "  Input Text:      'Christmas is on 25th Dec 2024.'\n",
      "  Extracted Date:  '25/12/2024'\n",
      "  Expected Output: '25/12/2024'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 10:\n",
      "  Input Text:      'The meeting is set for April 03, 2020.'\n",
      "  Extracted Date:  '03/04/2020'\n",
      "  Expected Output: '03/04/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 11:\n",
      "  Input Text:      'Her birthdate, noted as 1997-05-20, is in the records.'\n",
      "  Extracted Date:  '1997/05/2020'\n",
      "  Expected Output: '20/05/1997'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 12:\n",
      "  Input Text:      'Her appointment is on the 2nd of March, 2021.'\n",
      "  Extracted Date:  '02/03/2021'\n",
      "  Expected Output: '02/03/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 13:\n",
      "  Input Text:      'The exam date is 2021.11.10.'\n",
      "  Extracted Date:  '2021/11/2010'\n",
      "  Expected Output: '10/11/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 14:\n",
      "  Input Text:      'They got married on 12/12/12.'\n",
      "  Extracted Date:  '12/12/2012'\n",
      "  Expected Output: '12/12/2012'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 15:\n",
      "  Input Text:      'The workshop is on February 15th, 2022.'\n",
      "  Extracted Date:  '15/02/2022'\n",
      "  Expected Output: '15/02/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 16:\n",
      "  Input Text:      'Submit your report by 08/31/2021.'\n",
      "  Extracted Date:  '08/31/2021'\n",
      "  Expected Output: '31/08/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 17:\n",
      "  Input Text:      'The course starts on 1st July 2023.'\n",
      "  Extracted Date:  '01/07/2023'\n",
      "  Expected Output: '01/07/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 18:\n",
      "  Input Text:      'Independence Day is on 4th of July, 2022.'\n",
      "  Extracted Date:  '04/07/2022'\n",
      "  Expected Output: '04/07/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 19:\n",
      "  Input Text:      'His birthday is 1995/10/30.'\n",
      "  Extracted Date:  '1995/10/2030'\n",
      "  Expected Output: '30/10/1995'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 20:\n",
      "  Input Text:      'The new year begins on 01-01-2023.'\n",
      "  Extracted Date:  '01/01/2023'\n",
      "  Expected Output: '01/01/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 21:\n",
      "  Input Text:      'The seminar is on 03/14/2022.'\n",
      "  Extracted Date:  '03/14/2022'\n",
      "  Expected Output: '14/03/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 22:\n",
      "  Input Text:      'My last day is 31.08.2020.'\n",
      "  Extracted Date:  '31/08/2020'\n",
      "  Expected Output: '31/08/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 23:\n",
      "  Input Text:      'The due date is 2020-02-28.'\n",
      "  Extracted Date:  '2020/02/2028'\n",
      "  Expected Output: '28/02/2020'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 24:\n",
      "  Input Text:      'The holiday starts on Dec 20th, 2021.'\n",
      "  Extracted Date:  '20/12/2021'\n",
      "  Expected Output: '20/12/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 25:\n",
      "  Input Text:      'The conference will be held on 5th May 2023.'\n",
      "  Extracted Date:  '05/05/2023'\n",
      "  Expected Output: '05/05/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 26:\n",
      "  Input Text:      'They moved in on 12/25/2019.'\n",
      "  Extracted Date:  '12/25/2019'\n",
      "  Expected Output: '25/12/2019'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 27:\n",
      "  Input Text:      'The festival begins on March 17, 2022.'\n",
      "  Extracted Date:  '17/03/2022'\n",
      "  Expected Output: '17/03/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 28:\n",
      "  Input Text:      'The ceremony is on 11.11.2021.'\n",
      "  Extracted Date:  '11/11/2021'\n",
      "  Expected Output: '11/11/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 29:\n",
      "  Input Text:      'The event is on 2023/07/04.'\n",
      "  Extracted Date:  '2023/07/2004'\n",
      "  Expected Output: '04/07/2023'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 30:\n",
      "  Input Text:      'Her graduation is on May 30th, 2022.'\n",
      "  Extracted Date:  '30/05/2022'\n",
      "  Expected Output: '30/05/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 31:\n",
      "  Input Text:      'The release date is 2021-09-09.'\n",
      "  Extracted Date:  '2021/09/2009'\n",
      "  Expected Output: '09/09/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 32:\n",
      "  Input Text:      'The interview is on 1/2/2022.'\n",
      "  Extracted Date:  '01/02/2022'\n",
      "  Expected Output: '01/02/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 33:\n",
      "  Input Text:      'The celebration is on 2022-10-10.'\n",
      "  Extracted Date:  '2022/10/2010'\n",
      "  Expected Output: '10/10/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 34:\n",
      "  Input Text:      'His wedding is on 6th of August, 2020.'\n",
      "  Extracted Date:  '06/08/2020'\n",
      "  Expected Output: '06/08/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 35:\n",
      "  Input Text:      'She was born on 3rd March 1998.'\n",
      "  Extracted Date:  '03/03/1998'\n",
      "  Expected Output: '03/03/1998'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 36:\n",
      "  Input Text:      'The opening is on 10/10/2018.'\n",
      "  Extracted Date:  '10/10/2018'\n",
      "  Expected Output: '10/10/2018'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 37:\n",
      "  Input Text:      'The deadline is 2020.12.15.'\n",
      "  Extracted Date:  '2020/12/2015'\n",
      "  Expected Output: '15/12/2020'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 38:\n",
      "  Input Text:      'The party is on 31-12-2022.'\n",
      "  Extracted Date:  '31/12/2022'\n",
      "  Expected Output: '31/12/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 39:\n",
      "  Input Text:      'The workshop is on February 29, 2024.'\n",
      "  Extracted Date:  '29/02/2024'\n",
      "  Expected Output: '29/02/2024'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 40:\n",
      "  Input Text:      'Vacation starts on 07/15/2021.'\n",
      "  Extracted Date:  '07/15/2021'\n",
      "  Expected Output: '15/07/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 41:\n",
      "  Input Text:      'The application is due by 2022-03-03.'\n",
      "  Extracted Date:  '2022/03/2003'\n",
      "  Expected Output: '03/03/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 42:\n",
      "  Input Text:      'The tournament is on June 1st, 2021.'\n",
      "  Extracted Date:  '01/06/2021'\n",
      "  Expected Output: '01/06/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 43:\n",
      "  Input Text:      'The closing date is 08/08/2020.'\n",
      "  Extracted Date:  '08/08/2020'\n",
      "  Expected Output: '08/08/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 44:\n",
      "  Input Text:      'The concert is on 2020/09/09.'\n",
      "  Extracted Date:  '2020/09/2009'\n",
      "  Expected Output: '09/09/2020'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 45:\n",
      "  Input Text:      'The exam is on 01.01.2022.'\n",
      "  Extracted Date:  '01/01/2022'\n",
      "  Expected Output: '01/01/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 46:\n",
      "  Input Text:      'Independence Day is 2023-07-04.'\n",
      "  Extracted Date:  '2023/07/2004'\n",
      "  Expected Output: '04/07/2023'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 47:\n",
      "  Input Text:      'The last date is 30th November 2022.'\n",
      "  Extracted Date:  '30/11/2022'\n",
      "  Expected Output: '30/11/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 48:\n",
      "  Input Text:      'The conference is on 15th October 2023.'\n",
      "  Extracted Date:  '15/10/2023'\n",
      "  Expected Output: '15/10/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 49:\n",
      "  Input Text:      'His birthdate is 1990-05-20.'\n",
      "  Extracted Date:  '1990/05/2020'\n",
      "  Expected Output: '20/05/1990'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 50:\n",
      "  Input Text:      'The festival is on 12th August 2024.'\n",
      "  Extracted Date:  '12/08/2024'\n",
      "  Expected Output: '12/08/2024'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 51:\n",
      "  Input Text:      'Input'\n",
      "  Extracted Date:  'None'\n",
      "  Expected Output: 'Expected Output'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 52:\n",
      "  Input Text:      'We are planning to meet on March 5, 2023, for lunch.'\n",
      "  Extracted Date:  '05/03/2023'\n",
      "  Expected Output: '05/03/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 53:\n",
      "  Input Text:      'Her birthday, which she celebrates on 07/08/1990, is coming up soon.'\n",
      "  Extracted Date:  '07/08/1990'\n",
      "  Expected Output: '07/08/1990'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 54:\n",
      "  Input Text:      'The deadline, unfortunately, is set to 2022-12-31.'\n",
      "  Extracted Date:  '2022/12/2031'\n",
      "  Expected Output: '31/12/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 55:\n",
      "  Input Text:      'We first met on the 1st of January 2000 at the conference.'\n",
      "  Extracted Date:  '01/01/2000'\n",
      "  Expected Output: '01/01/2000'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 56:\n",
      "  Input Text:      'The concert, happening on 15th September 2021, will be amazing.'\n",
      "  Extracted Date:  '15/09/2021'\n",
      "  Expected Output: '15/09/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 57:\n",
      "  Input Text:      'Remember, the meeting is on 02.04.2022 at 10 AM.'\n",
      "  Extracted Date:  '02/04/2022'\n",
      "  Expected Output: '02/04/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 58:\n",
      "  Input Text:      'Let's wrap up the project by 5/6/19, so we can relax.'\n",
      "  Extracted Date:  '05/06/2019'\n",
      "  Expected Output: '05/06/2019'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 59:\n",
      "  Input Text:      'His birth date, recorded as 1987/11/23, was a memorable day.'\n",
      "  Extracted Date:  '1987/11/2023'\n",
      "  Expected Output: '23/11/1987'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 60:\n",
      "  Input Text:      'We celebrate Christmas every year on 25th Dec, including 2024.'\n",
      "  Extracted Date:  'None'\n",
      "  Expected Output: '25/12/2024'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 61:\n",
      "  Input Text:      'The meeting is rescheduled to April 03, 2020, as per the latest update.'\n",
      "  Extracted Date:  '03/04/2020'\n",
      "  Expected Output: '03/04/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 62:\n",
      "  Input Text:      'Their anniversary is marked on the 2nd of March, 2021.'\n",
      "  Extracted Date:  '02/03/2021'\n",
      "  Expected Output: '02/03/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 63:\n",
      "  Input Text:      'The official exam date is now 2021.11.10, per the new schedule.'\n",
      "  Extracted Date:  '2021/11/2010'\n",
      "  Expected Output: '10/11/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 64:\n",
      "  Input Text:      'They celebrated their wedding on 12/12/12 in grand style.'\n",
      "  Extracted Date:  '12/12/2012'\n",
      "  Expected Output: '12/12/2012'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 65:\n",
      "  Input Text:      'Our next workshop is scheduled for February 15th, 2022.'\n",
      "  Extracted Date:  '15/02/2022'\n",
      "  Expected Output: '15/02/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 66:\n",
      "  Input Text:      'The submission deadline, noted as 08/31/2021, is fast approaching.'\n",
      "  Extracted Date:  '08/31/2021'\n",
      "  Expected Output: '31/08/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 67:\n",
      "  Input Text:      'The course officially begins on 1st July 2023.'\n",
      "  Extracted Date:  '01/07/2023'\n",
      "  Expected Output: '01/07/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 68:\n",
      "  Input Text:      'We celebrate Independence Day on the 4th of July every year, including 2022.'\n",
      "  Extracted Date:  'None'\n",
      "  Expected Output: '04/07/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 69:\n",
      "  Input Text:      'He mentioned that his birth date is 1995/10/30 in the form.'\n",
      "  Extracted Date:  '1995/10/2030'\n",
      "  Expected Output: '30/10/1995'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 70:\n",
      "  Input Text:      'The new year's celebration begins on 01-01-2023 at midnight.'\n",
      "  Extracted Date:  '01/01/2023'\n",
      "  Expected Output: '01/01/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 71:\n",
      "  Input Text:      'We scheduled the seminar for 03/14/2022, don't forget.'\n",
      "  Extracted Date:  '03/14/2022'\n",
      "  Expected Output: '14/03/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 72:\n",
      "  Input Text:      'My final working day here is noted as 31.08.2020.'\n",
      "  Extracted Date:  '31/08/2020'\n",
      "  Expected Output: '31/08/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 73:\n",
      "  Input Text:      'The project's due date is officially 2020-02-28.'\n",
      "  Extracted Date:  '2020/02/2028'\n",
      "  Expected Output: '28/02/2020'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 74:\n",
      "  Input Text:      'The holiday vacation starts on Dec 20th, 2021, for everyone.'\n",
      "  Extracted Date:  '20/12/2021'\n",
      "  Expected Output: '20/12/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 75:\n",
      "  Input Text:      'The conference, marked for 5th May 2023, is a significant event.'\n",
      "  Extracted Date:  '05/05/2023'\n",
      "  Expected Output: '05/05/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 76:\n",
      "  Input Text:      'They officially moved in on 12/25/2019.'\n",
      "  Extracted Date:  '12/25/2019'\n",
      "  Expected Output: '25/12/2019'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 77:\n",
      "  Input Text:      'Our festival starts on March 17, 2022, with a parade.'\n",
      "  Extracted Date:  '17/03/2022'\n",
      "  Expected Output: '17/03/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 78:\n",
      "  Input Text:      'The ceremony date is fixed as 11.11.2021.'\n",
      "  Extracted Date:  '11/11/2021'\n",
      "  Expected Output: '11/11/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 79:\n",
      "  Input Text:      'The big event is planned for 2023/07/04, so mark your calendars.'\n",
      "  Extracted Date:  '2023/07/2004'\n",
      "  Expected Output: '04/07/2023'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 80:\n",
      "  Input Text:      'Her graduation day is set for May 30th, 2022.'\n",
      "  Extracted Date:  '30/05/2022'\n",
      "  Expected Output: '30/05/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 81:\n",
      "  Input Text:      'The software release date is set for 2021-09-09.'\n",
      "  Extracted Date:  '2021/09/2009'\n",
      "  Expected Output: '09/09/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 82:\n",
      "  Input Text:      'The job interview is on 1/2/2022, don't be late.'\n",
      "  Extracted Date:  '01/02/2022'\n",
      "  Expected Output: '01/02/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 83:\n",
      "  Input Text:      'The grand celebration is on 2022-10-10, a date to remember.'\n",
      "  Extracted Date:  '2022/10/2010'\n",
      "  Expected Output: '10/10/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 84:\n",
      "  Input Text:      'The wedding is on 6th of August, 2020, in the evening.'\n",
      "  Extracted Date:  '06/08/2020'\n",
      "  Expected Output: '06/08/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 85:\n",
      "  Input Text:      'She mentioned she was born on the 3rd of March 1998.'\n",
      "  Extracted Date:  '03/03/1998'\n",
      "  Expected Output: '03/03/1998'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 86:\n",
      "  Input Text:      'The official opening date is 10/10/2018, as per the announcement.'\n",
      "  Extracted Date:  '10/10/2018'\n",
      "  Expected Output: '10/10/2018'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 87:\n",
      "  Input Text:      'The critical deadline is 2020.12.15, please note it.'\n",
      "  Extracted Date:  '2020/12/2015'\n",
      "  Expected Output: '15/12/2020'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 88:\n",
      "  Input Text:      'The New Year's Eve party is on 31-12-2022, join us!'\n",
      "  Extracted Date:  '31/12/2022'\n",
      "  Expected Output: '31/12/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 89:\n",
      "  Input Text:      'The next workshop is on February 29, 2024, due to the leap year.'\n",
      "  Extracted Date:  '29/02/2024'\n",
      "  Expected Output: '29/02/2024'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 90:\n",
      "  Input Text:      'Vacation officially starts on 07/15/2021, get ready.'\n",
      "  Extracted Date:  '07/15/2021'\n",
      "  Expected Output: '15/07/2021'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 91:\n",
      "  Input Text:      'The application submission date is 2022-03-03.'\n",
      "  Extracted Date:  '2022/03/2003'\n",
      "  Expected Output: '03/03/2022'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 92:\n",
      "  Input Text:      'The tournament begins on June 1st, 2021, early in the morning.'\n",
      "  Extracted Date:  '01/06/2021'\n",
      "  Expected Output: '01/06/2021'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 93:\n",
      "  Input Text:      'The registration closing date is 08/08/2020.'\n",
      "  Extracted Date:  '08/08/2020'\n",
      "  Expected Output: '08/08/2020'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 94:\n",
      "  Input Text:      'The music concert is scheduled for 2020/09/09.'\n",
      "  Extracted Date:  '2020/09/2009'\n",
      "  Expected Output: '09/09/2020'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 95:\n",
      "  Input Text:      'The exam will be held on 01.01.2022, start preparing.'\n",
      "  Extracted Date:  '01/01/2022'\n",
      "  Expected Output: '01/01/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 96:\n",
      "  Input Text:      'We celebrate Independence Day on 2023-07-04, as always.'\n",
      "  Extracted Date:  '2023/07/2004'\n",
      "  Expected Output: '04/07/2023'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 97:\n",
      "  Input Text:      'The final date for submission is 30th November 2022.'\n",
      "  Extracted Date:  '30/11/2022'\n",
      "  Expected Output: '30/11/2022'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 98:\n",
      "  Input Text:      'The annual conference is on 15th October 2023, mark your calendars.'\n",
      "  Extracted Date:  '15/10/2023'\n",
      "  Expected Output: '15/10/2023'\n",
      "  Status:          PASS\n",
      "------------------------------\n",
      "Test Case 99:\n",
      "  Input Text:      'His birthdate, noted as 1990-05-20, is in the records.'\n",
      "  Extracted Date:  '1990/05/2020'\n",
      "  Expected Output: '20/05/1990'\n",
      "  Status:          FAIL\n",
      "------------------------------\n",
      "Test Case 100:\n",
      "  Input Text:      'The festival will be celebrated on 12th August 2024, with grand events.'\n",
      "  Extracted Date:  '12/08/2024'\n",
      "  Expected Output: '12/08/2024'\n",
      "  Status:          PASS\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_date(text):\n",
    "    \"\"\"\n",
    "    Parses a date from a given text string and formats it as DD/MM/YYYY.\n",
    "    This function uses regular expressions to handle various date formats.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing a date.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted and formatted date in DD/MM/YYYY format, or None if no date is found.\n",
    "    \"\"\"\n",
    "    # A dictionary to map month names to numbers\n",
    "    month_mapping = {\n",
    "        'january': '01', 'jan': '01',\n",
    "        'february': '02', 'feb': '02',\n",
    "        'march': '03', 'mar': '03',\n",
    "        'april': '04', 'apr': '04',\n",
    "        'may': '05',\n",
    "        'june': '06', 'jun': '06',\n",
    "        'july': '07', 'jul': '06',\n",
    "        'august': '08', 'aug': '08',\n",
    "        'september': '09', 'sep': '09',\n",
    "        'october': '10', 'oct': '10',\n",
    "        'november': '11', 'nov': '11',\n",
    "        'december': '12', 'dec': '12'\n",
    "    }\n",
    "\n",
    "    # Regex patterns for different date formats\n",
    "    patterns = [\n",
    "        # YYYY-MM-DD, YYYY.MM.DD\n",
    "        r'(\\d{4})[-.\\/](\\d{1,2})[-.\\/](\\d{1,2})',\n",
    "        # DD-MM-YYYY, DD/MM/YYYY, DD.MM.YYYY\n",
    "        r'(\\d{1,2})[-.\\/](\\d{1,2})[-.\\/](\\d{4})',\n",
    "        # MM/DD/YY or YYYY\n",
    "        r'(\\d{1,2})[-.\\/](\\d{1,2})[-.\\/](\\d{2,4})',\n",
    "        # Month Day, Year (e.g., March 5, 2023)\n",
    "        r'(?:on|for|is on|starts on|is set for|was born on|on the) (?:the )?(\\d{1,2})(?:st|nd|rd|th)?(?: of)? ([a-zA-Z]+)[,.]? (\\d{4})',\n",
    "        # Month Day, Year (e.g., March 5, 2023) without 'on the' part\n",
    "        r'([a-zA-Z]+) (\\d{1,2})(?:st|nd|rd|th)?[,.]? (\\d{4})',\n",
    "        # Day Month Year (e.g., 5th March 2023)\n",
    "        r'(\\d{1,2})(?:st|nd|rd|th)?(?: of)? ([a-zA-Z]+)[,.]? (\\d{4})'\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            parts = match.groups()\n",
    "            \n",
    "            # Case: DD-MM-YYYY or similar\n",
    "            if len(parts) == 3 and parts[0].isdigit() and parts[1].isdigit():\n",
    "                day = parts[0]\n",
    "                month = parts[1]\n",
    "                year = parts[2]\n",
    "            \n",
    "            # Case: YYYY-MM-DD or similar\n",
    "            elif len(parts) == 3 and parts[0].isdigit() and parts[1].isdigit() and len(parts[0]) == 4:\n",
    "                day = parts[2]\n",
    "                month = parts[1]\n",
    "                year = parts[0]\n",
    "\n",
    "            # Case: Month Day, Year\n",
    "            elif len(parts) == 3 and not parts[0].isdigit() and parts[1].isdigit():\n",
    "                month = month_mapping.get(parts[0].lower())\n",
    "                day = parts[1]\n",
    "                year = parts[2]\n",
    "                if not month:\n",
    "                    continue\n",
    "            \n",
    "            # Case: Day Month, Year or Month Day, Year\n",
    "            elif len(parts) == 3 and parts[0].isdigit() and not parts[1].isdigit():\n",
    "                day = parts[0]\n",
    "                month = month_mapping.get(parts[1].lower())\n",
    "                year = parts[2]\n",
    "                if not month:\n",
    "                    continue\n",
    "            \n",
    "            # Format the day and month with leading zeros if necessary\n",
    "            day = day.zfill(2)\n",
    "            month = month.zfill(2)\n",
    "            \n",
    "            # Handle 2-digit years\n",
    "            if len(year) == 2:\n",
    "                year = f\"20{year}\" if int(year) < 50 else f\"19{year}\"\n",
    "\n",
    "            return f\"{day}/{month}/{year}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def process_testcases(filename):\n",
    "    \"\"\"\n",
    "    Reads a CSV file of test cases, processes each line, and prints the output.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    print(\"Running date parser test cases...\")\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header row\n",
    "        for i, row in enumerate(reader):\n",
    "            input_text = row[0]\n",
    "            expected_output = row[1]\n",
    "            extracted_date = parse_date(input_text)\n",
    "            print(f\"Test Case {i+1}:\")\n",
    "            print(f\"  Input Text:      '{input_text}'\")\n",
    "            print(f\"  Extracted Date:  '{extracted_date}'\")\n",
    "            print(f\"  Expected Output: '{expected_output}'\")\n",
    "            print(f\"  Status:          {'PASS' if extracted_date == expected_output else 'FAIL'}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_testcases(\"date_parser_testcases.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e8db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.67.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\yatha\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (3.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cupyx\\scipy\\sparse\\_base.py:10: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.2)\n",
      "  import scipy.sparse as _sparse\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 3.4 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.1/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.8/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "This nsubj\n",
      "is ROOT\n",
      "her poss\n",
      "book attr\n",
      ". punct\n",
      "\n",
      "Give ROOT\n",
      "the det\n",
      "book dobj\n",
      "back advmod\n",
      "to prep\n",
      "her pobj\n",
      ". punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "text = [\n",
    "    \"This is her book.\",\n",
    "    \"Give the book back to her.\"\n",
    "]\n",
    "\n",
    "\n",
    "for t in text:\n",
    "    doc = nlp(t)\n",
    "\n",
    "    for tok in doc:\n",
    "        print(tok.text, tok.dep_)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcbf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f10fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pronoun transformer test cases...\n",
      "Test Case 1:\n",
      "  Input Text:       'He is going to the market.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'She is going to the market.'\n",
      "  Expected Output:  'She is going to the market.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 2:\n",
      "  Input Text:       'His book is on the table.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'Her book is on the table.'\n",
      "  Expected Output:  'Her book is on the table.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 3:\n",
      "  Input Text:       'I saw him yesterday.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'I saw her yesterday.'\n",
      "  Expected Output:  'I saw her yesterday.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 4:\n",
      "  Input Text:       'He hurt himself.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'She hurt herself.'\n",
      "  Expected Output:  'She hurt herself.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 5:\n",
      "  Input Text:       'I called him last night.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'I called her last night.'\n",
      "  Expected Output:  'I called her last night.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 6:\n",
      "  Input Text:       'That is his car.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'That is her car.'\n",
      "  Expected Output:  'That is her car.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 7:\n",
      "  Input Text:       'He told me about his trip.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'She told me about her trip.'\n",
      "  Expected Output:  'She told me about her trip.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 8:\n",
      "  Input Text:       'The teacher gave him a warning.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'The teacher gave her a warning.'\n",
      "  Expected Output:  'The teacher gave her a warning.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 9:\n",
      "  Input Text:       'He blames himself for the mistake.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'She blames herself for the mistake.'\n",
      "  Expected Output:  'She blames herself for the mistake.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 10:\n",
      "  Input Text:       'He brought his laptop.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'She brought her laptop.'\n",
      "  Expected Output:  'She brought her laptop.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 11:\n",
      "  Input Text:       'He made it himself.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'She made it herself.'\n",
      "  Expected Output:  'She made it herself.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 12:\n",
      "  Input Text:       'I don’t like his attitude.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'I don’t like her attitude.'\n",
      "  Expected Output:  'I don’t like her attitude.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 13:\n",
      "  Input Text:       'Tell him to come here.'\n",
      "  Target Gender:    'female'\n",
      "  Transformed Text: 'Tell her to come here.'\n",
      "  Expected Output:  'Tell her to come here.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 14:\n",
      "  Input Text:       'She is going to the market.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'He is going to the market.'\n",
      "  Expected Output:  'He is going to the market.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 15:\n",
      "  Input Text:       'Her book is on the table.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'Him book is on the table.'\n",
      "  Expected Output:  'His book is on the table.'\n",
      "  Status:           FAIL\n",
      "------------------------------\n",
      "Test Case 16:\n",
      "  Input Text:       'I saw her yesterday.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'I saw him yesterday.'\n",
      "  Expected Output:  'I saw him yesterday.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 17:\n",
      "  Input Text:       'She hurt herself.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'He hurt himself.'\n",
      "  Expected Output:  'He hurt himself.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 18:\n",
      "  Input Text:       'I called her last night.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'I called him last night.'\n",
      "  Expected Output:  'I called him last night.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 19:\n",
      "  Input Text:       'That is her car.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'That is him car.'\n",
      "  Expected Output:  'That is his car.'\n",
      "  Status:           FAIL\n",
      "------------------------------\n",
      "Test Case 20:\n",
      "  Input Text:       'She told me about her trip.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'He told me about him trip.'\n",
      "  Expected Output:  'He told me about his trip.'\n",
      "  Status:           FAIL\n",
      "------------------------------\n",
      "Test Case 21:\n",
      "  Input Text:       'The teacher gave her a warning.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'The teacher gave him a warning.'\n",
      "  Expected Output:  'The teacher gave him a warning.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 22:\n",
      "  Input Text:       'She blames herself for the mistake.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'He blames himself for the mistake.'\n",
      "  Expected Output:  'He blames himself for the mistake.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 23:\n",
      "  Input Text:       'She brought her laptop.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'He brought him laptop.'\n",
      "  Expected Output:  'He brought his laptop.'\n",
      "  Status:           FAIL\n",
      "------------------------------\n",
      "Test Case 24:\n",
      "  Input Text:       'She made it herself.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'He made it himself.'\n",
      "  Expected Output:  'He made it himself.'\n",
      "  Status:           PASS\n",
      "------------------------------\n",
      "Test Case 25:\n",
      "  Input Text:       'I don’t like her attitude.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'I don’t like him attitude.'\n",
      "  Expected Output:  'I don’t like his attitude.'\n",
      "  Status:           FAIL\n",
      "------------------------------\n",
      "Test Case 26:\n",
      "  Input Text:       'Tell her to come here.'\n",
      "  Target Gender:    'male'\n",
      "  Transformed Text: 'Tell him to come here.'\n",
      "  Expected Output:  'Tell him to come here.'\n",
      "  Status:           PASS\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# Note: As you correctly pointed out in your previous error,\n",
    "# the spacy model 'en_core_web_sm' must be downloaded separately.\n",
    "# Ensure you have run:\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def transform_pronouns(text, target_gender):\n",
    "    \"\"\"\n",
    "    Transforms gendered pronouns in a sentence to the opposite gender.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input sentence.\n",
    "        target_gender (str): The target gender ('male' or 'female').\n",
    "\n",
    "    Returns:\n",
    "        str: The sentence with transformed pronouns.\n",
    "    \"\"\"\n",
    "    # A single, comprehensive mapping for pronoun transformations.\n",
    "    pronoun_map = {\n",
    "        'he': 'she', 'He': 'She', 'HE': 'SHE',\n",
    "        'she': 'he', 'She': 'He', 'SHE': 'HE',\n",
    "        'him': 'her', 'Him': 'Her', 'HIM': 'HER',\n",
    "        'her': 'him', 'Her': 'Him', 'HER': 'HIM',\n",
    "        'his': 'her', 'His': 'Her', 'HIS': 'HER',\n",
    "        'hers': 'his', 'Hers': 'His', 'HERS': 'HIS',\n",
    "        'himself': 'herself', 'Himself': 'Herself', 'HIMSELF': 'HERSELF',\n",
    "        'herself': 'himself', 'Herself': 'Himself', 'HERSELF': 'HIMSELF'\n",
    "    }\n",
    "\n",
    "    # Decide which direction to swap based on the target gender.\n",
    "    if target_gender.lower() == 'female':\n",
    "        # Create a mapping to convert male pronouns to female ones.\n",
    "        swap_map = {\n",
    "            'he': 'she', 'He': 'She', 'HE': 'SHE',\n",
    "            'him': 'her', 'Him': 'Her', 'HIM': 'HER',\n",
    "            'his': 'her', 'His': 'Her', 'HIS': 'HER',\n",
    "            'himself': 'herself', 'Himself': 'Herself', 'HIMSELF': 'HERSELF'\n",
    "        }\n",
    "    elif target_gender.lower() == 'male':\n",
    "        # Create a mapping to convert female pronouns to male ones.\n",
    "        swap_map = {\n",
    "            'she': 'he', 'She': 'He', 'SHE': 'HE',\n",
    "            'her': 'him', 'Her': 'Him', 'HER': 'HIM',\n",
    "            'hers': 'his', 'Hers': 'His', 'HERS': 'HIS',\n",
    "            'herself': 'himself', 'Herself': 'Himself', 'HERSELF': 'HIMSELF'\n",
    "        }\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "    words = text.split()\n",
    "    transformed_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Check if the word, after stripping punctuation, is a key in our swap map.\n",
    "        clean_word = re.sub(r'[^a-zA-Z]', '', word)\n",
    "        \n",
    "        if clean_word in swap_map:\n",
    "            transformed_word = swap_map[clean_word]\n",
    "            # Preserve the original capitalization and punctuation.\n",
    "            # For example, if the word was \"He.\", the new word should be \"She.\"\n",
    "            if not clean_word == word:\n",
    "                transformed_word += word[len(clean_word):]\n",
    "            transformed_words.append(transformed_word)\n",
    "        else:\n",
    "            transformed_words.append(word)\n",
    "\n",
    "    # Join the words back into a sentence.\n",
    "    return \" \".join(transformed_words)\n",
    "\n",
    "def process_testcases(filename):\n",
    "    \"\"\"\n",
    "    Reads a CSV of test cases, processes each line, and prints the output.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    print(\"Running pronoun transformer test cases...\")\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header row\n",
    "        for i, row in enumerate(reader):\n",
    "            input_text = row[0]\n",
    "            target_gender = row[1]\n",
    "            expected_output = row[2]\n",
    "            \n",
    "            transformed_text = transform_pronouns(input_text, target_gender)\n",
    "\n",
    "            print(f\"Test Case {i+1}:\")\n",
    "            print(f\"  Input Text:       '{input_text}'\")\n",
    "            print(f\"  Target Gender:    '{target_gender}'\")\n",
    "            print(f\"  Transformed Text: '{transformed_text}'\")\n",
    "            print(f\"  Expected Output:  '{expected_output}'\")\n",
    "            print(f\"  Status:           {'PASS' if transformed_text.strip() == expected_output.strip() else 'FAIL'}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_testcases(\"pronoun_testcases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa0b4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.18.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (4.67.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.32.3)\n",
      "Collecting torch>=2.3.0 (from torchtext)\n",
      "  Using cached torch-2.8.0-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.3.0->torchtext) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.3.0->torchtext)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.3.0->torchtext) (2024.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yatha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\yatha\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Downloading torchtext-0.18.0-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/1.9 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/1.9 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 1.5 MB/s eta 0:00:00\n",
      "Using cached torch-2.8.0-cp311-cp311-win_amd64.whl (241.4 MB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 2.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 1.6/6.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.1/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.1/6.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch, torchtext\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.13.1\n",
      "\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "    Uninstalling sympy-1.13.1:\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "  Attempting uninstall: torch\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "    Found existing installation: torch 2.2.2+cpu\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "    Uninstalling torch-2.2.2+cpu:\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "      Successfully uninstalled torch-2.2.2+cpu\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   -------------------------- ------------- 2/3 [torchtext]\n",
      "   -------------------------- ------------- 2/3 [torchtext]\n",
      "   -------------------------- ------------- 2/3 [torchtext]\n",
      "   -------------------------- ------------- 2/3 [torchtext]\n",
      "   -------------------------- ------------- 2/3 [torchtext]\n",
      "   -------------------------- ------------- 2/3 [torchtext]\n",
      "   ---------------------------------------- 3/3 [torchtext]\n",
      "\n",
      "Successfully installed sympy-1.14.0 torch-2.8.0 torchtext-0.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Yatha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.2.2+cpu requires torch==2.2.2, but you have torch 2.8.0 which is incompatible.\n",
      "torchvision 0.17.2+cpu requires torch==2.2.2, but you have torch 2.8.0 which is incompatible.\n",
      "ultralytics 8.3.93 requires numpy<=2.1.1,>=1.23.0, but you have numpy 2.3.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc1cdd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "--- Part 1: Training with GloVe Embeddings ---\n",
      "\n",
      "--- Training GloVe + Vanilla RNN ---\n",
      "Epoch: 01 | Train Loss: 0.696 | Train Acc: 50.39% | Val. Loss: 0.694 | Val. Acc: 50.73%\n",
      "Epoch: 02 | Train Loss: 0.697 | Train Acc: 50.03% | Val. Loss: 0.696 | Val. Acc: 50.91%\n",
      "Epoch: 03 | Train Loss: 0.696 | Train Acc: 49.82% | Val. Loss: 0.699 | Val. Acc: 49.05%\n",
      "Epoch: 04 | Train Loss: 0.696 | Train Acc: 50.59% | Val. Loss: 0.694 | Val. Acc: 49.83%\n",
      "Epoch: 05 | Train Loss: 0.696 | Train Acc: 50.51% | Val. Loss: 0.701 | Val. Acc: 49.79%\n",
      "\n",
      "--- Training GloVe + LSTM ---\n",
      "Epoch: 01 | Train Loss: 0.692 | Train Acc: 51.54% | Val. Loss: 0.690 | Val. Acc: 52.34%\n",
      "Epoch: 02 | Train Loss: 0.692 | Train Acc: 51.91% | Val. Loss: 0.693 | Val. Acc: 50.93%\n",
      "Epoch: 03 | Train Loss: 0.689 | Train Acc: 52.59% | Val. Loss: 0.693 | Val. Acc: 51.27%\n",
      "Epoch: 04 | Train Loss: 0.687 | Train Acc: 53.50% | Val. Loss: 0.694 | Val. Acc: 51.55%\n",
      "Epoch: 05 | Train Loss: 0.637 | Train Acc: 62.87% | Val. Loss: 0.829 | Val. Acc: 53.43%\n",
      "\n",
      "--- Part 2: Training with On-the-fly Embeddings ---\n",
      "\n",
      "--- Training On-the-fly + Vanilla RNN ---\n",
      "Epoch: 01 | Train Loss: 0.696 | Train Acc: 50.23% | Val. Loss: 0.694 | Val. Acc: 50.17%\n",
      "Epoch: 02 | Train Loss: 0.698 | Train Acc: 50.19% | Val. Loss: 0.693 | Val. Acc: 49.96%\n",
      "Epoch: 03 | Train Loss: 0.696 | Train Acc: 50.40% | Val. Loss: 0.693 | Val. Acc: 50.36%\n",
      "Epoch: 04 | Train Loss: 0.693 | Train Acc: 52.10% | Val. Loss: 0.705 | Val. Acc: 49.98%\n",
      "Epoch: 05 | Train Loss: 0.695 | Train Acc: 51.15% | Val. Loss: 0.697 | Val. Acc: 50.40%\n",
      "\n",
      "--- Training On-the-fly + LSTM ---\n",
      "Epoch: 01 | Train Loss: 0.694 | Train Acc: 50.53% | Val. Loss: 0.693 | Val. Acc: 50.69%\n",
      "Epoch: 02 | Train Loss: 0.689 | Train Acc: 53.31% | Val. Loss: 0.700 | Val. Acc: 49.85%\n",
      "Epoch: 03 | Train Loss: 0.676 | Train Acc: 56.27% | Val. Loss: 0.619 | Val. Acc: 69.49%\n",
      "Epoch: 04 | Train Loss: 0.490 | Train Acc: 77.02% | Val. Loss: 0.410 | Val. Acc: 82.02%\n",
      "Epoch: 05 | Train Loss: 0.279 | Train Acc: 89.17% | Val. Loss: 0.371 | Val. Acc: 84.71%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import GloVe\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads the IMDB dataset, cleans the text, and splits into train/test sets.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the IMDB Dataset CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing lists of train reviews, train labels,\n",
    "               test reviews, and test labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Simple text cleaning\n",
    "    df['review'] = df['review'].apply(lambda x: re.sub(r'<br\\s*/>', ' ', x).strip())\n",
    "    \n",
    "    # Convert sentiment labels to numerical values (0 for 'negative', 1 for 'positive')\n",
    "    df['sentiment'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    reviews_train, reviews_test, labels_train, labels_test = train_test_split(\n",
    "        df['review'].tolist(), \n",
    "        df['sentiment'].tolist(), \n",
    "        test_size=0.2, \n",
    "        random_state=SEED\n",
    "    )\n",
    "    return reviews_train, reviews_test, labels_train, labels_test\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for text data.\n",
    "    \"\"\"\n",
    "    def __init__(self, texts, labels, vocab, max_len):\n",
    "        self.texts = [self.tokenize(text, vocab, max_len) for text in texts]\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx]), torch.tensor(self.labels[idx])\n",
    "    \n",
    "    def tokenize(self, text, vocab, max_len):\n",
    "        \"\"\"\n",
    "        Tokenizes and pads/truncates a text.\n",
    "        The function is corrected to use the standard Python dictionary `vocab`\n",
    "        instead of a non-existent `.stoi` attribute.\n",
    "        \"\"\"\n",
    "        tokens = text.lower().split()\n",
    "        \n",
    "        # Look up word indices, defaulting to the '<unk>' token's index for unknown words.\n",
    "        indexed_tokens = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "        \n",
    "        if len(indexed_tokens) < max_len:\n",
    "            # Pad with the index of the padding token (0)\n",
    "            indexed_tokens += [vocab['<pad>']] * (max_len - len(indexed_tokens))\n",
    "        elif len(indexed_tokens) > max_len:\n",
    "            # Truncate\n",
    "            indexed_tokens = indexed_tokens[:max_len]\n",
    "        \n",
    "        return indexed_tokens\n",
    "\n",
    "# --- 2. GloVe Embeddings & Vocabulary ---\n",
    "def build_glove_vocab(reviews_train):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary and loads GloVe embeddings.\n",
    "    \n",
    "    Note: This will download the GloVe embeddings file (~822MB) the first time it's run.\n",
    "    \"\"\"\n",
    "    counter = Counter(' '.join(reviews_train).lower().split())\n",
    "    glove = GloVe(name='6B', dim=100)\n",
    "    \n",
    "    # Build a vocabulary that includes all words in the dataset and in GloVe\n",
    "    vocab_itos = ['<pad>', '<unk>'] + [word for word in counter if word in glove.stoi]\n",
    "    vocab_stoi = {word: i for i, word in enumerate(vocab_itos)}\n",
    "    \n",
    "    # Create the embedding matrix\n",
    "    weights_matrix = torch.zeros(len(vocab_itos), glove.dim)\n",
    "    for i, word in enumerate(vocab_itos):\n",
    "        if word in glove.stoi:\n",
    "            weights_matrix[i] = glove[word]\n",
    "    \n",
    "    return vocab_stoi, weights_matrix\n",
    "\n",
    "# --- 3. Model Architectures ---\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"Vanilla RNN with an Embedding layer.\"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=0)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "            \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden_output = hidden.squeeze(0) # Use the last hidden state\n",
    "        return self.fc(hidden_output)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"LSTM with an Embedding layer.\"\"\"\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=0)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "            \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden_output = hidden.squeeze(0) # Use the last hidden state\n",
    "        return self.fc(hidden_output)\n",
    "\n",
    "# --- 4. Training and Evaluation Functions ---\n",
    "def train_model(model, iterator, optimizer, criterion):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, labels = batch\n",
    "        predictions = model(text).squeeze(1)\n",
    "        \n",
    "        # Calculate loss and accuracy\n",
    "        loss = criterion(predictions, labels.float())\n",
    "        acc = binary_accuracy(predictions, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_model(model, iterator, criterion):\n",
    "    \"\"\"Evaluates the model's performance.\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, labels = batch\n",
    "            predictions = model(text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, labels.float())\n",
    "            acc = binary_accuracy(predictions, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"Calculates accuracy for binary classification.\"\"\"\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "# --- 5. Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Hyperparameters\n",
    "    MAX_LEN = 256\n",
    "    EMBEDDING_DIM = 100\n",
    "    HIDDEN_DIM = 256\n",
    "    OUTPUT_DIM = 1\n",
    "    N_EPOCHS = 5\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 1e-3\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    reviews_train, reviews_test, labels_train, labels_test = load_and_preprocess_data('IMDB Dataset.csv')\n",
    "\n",
    "    # --- Part 1: GloVe Embeddings with Vanilla RNN and LSTMs ---\n",
    "    print(\"\\n--- Part 1: Training with GloVe Embeddings ---\")\n",
    "    \n",
    "    # Build vocabulary and get pre-trained weights\n",
    "    vocab_stoi, weights_matrix = build_glove_vocab(reviews_train)\n",
    "    VOCAB_SIZE = len(vocab_stoi)\n",
    "\n",
    "    train_data = TextDataset(reviews_train, labels_train, vocab_stoi, MAX_LEN)\n",
    "    test_data = TextDataset(reviews_test, labels_test, vocab_stoi, MAX_LEN)\n",
    "    \n",
    "    train_iterator = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_iterator = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # 1.1 GloVe with Vanilla RNN\n",
    "    print(\"\\n--- Training GloVe + Vanilla RNN ---\")\n",
    "    rnn_glove_model = RNN(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, VOCAB_SIZE, weights_matrix).to(device)\n",
    "    optimizer_rnn_glove = optim.Adam(rnn_glove_model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    \n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_loss, train_acc = train_model(rnn_glove_model, train_iterator, optimizer_rnn_glove, criterion)\n",
    "        valid_loss, valid_acc = evaluate_model(rnn_glove_model, test_iterator, criterion)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "        \n",
    "    # 1.2 GloVe with LSTM\n",
    "    print(\"\\n--- Training GloVe + LSTM ---\")\n",
    "    lstm_glove_model = LSTM(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, VOCAB_SIZE, weights_matrix).to(device)\n",
    "    optimizer_lstm_glove = optim.Adam(lstm_glove_model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_loss, train_acc = train_model(lstm_glove_model, train_iterator, optimizer_lstm_glove, criterion)\n",
    "        valid_loss, valid_acc = evaluate_model(lstm_glove_model, test_iterator, criterion)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    # --- Part 2: On-the-fly Embeddings with Vanilla RNN and LSTMs ---\n",
    "    print(\"\\n--- Part 2: Training with On-the-fly Embeddings ---\")\n",
    "    \n",
    "    # A simple vocabulary for on-the-fly embeddings. No need for GloVe.\n",
    "    counter_simple = Counter(' '.join(reviews_train).lower().split())\n",
    "    vocab_stoi_simple = {word: i+2 for i, word in enumerate(counter_simple)}\n",
    "    vocab_stoi_simple['<pad>'] = 0\n",
    "    vocab_stoi_simple['<unk>'] = 1\n",
    "    VOCAB_SIZE_SIMPLE = len(vocab_stoi_simple)\n",
    "    \n",
    "    train_data_simple = TextDataset(reviews_train, labels_train, vocab_stoi_simple, MAX_LEN)\n",
    "    test_data_simple = TextDataset(reviews_test, labels_test, vocab_stoi_simple, MAX_LEN)\n",
    "    \n",
    "    train_iterator_simple = DataLoader(train_data_simple, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_iterator_simple = DataLoader(test_data_simple, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # 2.1 On-the-fly Embeddings with Vanilla RNN\n",
    "    print(\"\\n--- Training On-the-fly + Vanilla RNN ---\")\n",
    "    rnn_simple_model = RNN(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, VOCAB_SIZE_SIMPLE).to(device)\n",
    "    optimizer_rnn_simple = optim.Adam(rnn_simple_model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_loss, train_acc = train_model(rnn_simple_model, train_iterator_simple, optimizer_rnn_simple, criterion)\n",
    "        valid_loss, valid_acc = evaluate_model(rnn_simple_model, test_iterator_simple, criterion)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    # 2.2 On-the-fly Embeddings with LSTM\n",
    "    print(\"\\n--- Training On-the-fly + LSTM ---\")\n",
    "    lstm_simple_model = LSTM(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, VOCAB_SIZE_SIMPLE).to(device)\n",
    "    optimizer_lstm_simple = optim.Adam(lstm_simple_model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(N_EPOCHS):\n",
    "        train_loss, train_acc = train_model(lstm_simple_model, train_iterator_simple, optimizer_lstm_simple, criterion)\n",
    "        valid_loss, valid_acc = evaluate_model(lstm_simple_model, test_iterator_simple, criterion)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd6715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
